# confluent elasticsearch connector doc: https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/index.html

# based on example: https://github.com/confluentinc/kafka-connect-elasticsearch/blob/master/config/quickstart-elasticsearch.properties

# all properties: https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/configuration_options.html#connector
connection.url=http://elasticsearch-master.kube-system.svc.cluster.local:9200
connector.class=io.confluent.connect.elasticsearch.ElasticsearchSinkConnector
tasks.max=1

 # TODO: we can decide this
name=elasticsearch-sink
# topics=test-elasticsearch-sink # TODO: topic names are based on tables, so will have multiple names. is there a `*` to match all? --> seems like SMT should handle this
# TODO: type under which the events will be registered in Elasticsearch. can we decide this?
key.ignore=false
behavior.on.null.values=delete

#### examples for hint ####

# debezium blog: https://debezium.io/blog/2018/01/17/streaming-to-elasticsearch/

# consume every topics from postgres source connector
# to check all current topics stored in kafka, run:
# $KAFKA_HOME/bin/kafka-topics.sh --list --bootstrap-server kafka-stack-release-0.kafka-stack-release-headless.kube-system.svc.cluster.local:9092

# Elasticsearch mapping name. Gets created automatically if doesn't exist
# type.name=kafka-connect
# type.name=_doc
# set type.name to blank, as suggested in this github issue (this will set type to default `_doc`. In es 7 it is discouraged to alter or have other type name):
# https://github.com/confluentinc/kafka-connect-elasticsearch/issues/342#issuecomment-539034678
type.name=

# Which topic to stream data from into Elasticsearch
# topics=appl_tracky.public.api_application,appl_tracky.public.api_company
# topics.regex=^.*api_company$
topics.regex=^appl_tracky[^.]*[.]public[.]api_(company|application)$
# topics.prefix=appl_tracky

# SMT (Single message transformation)
# transforms=unwrap,key
# transforms.unwrap.type=io.debezium.transforms.UnwrapFromEnvelope
transforms=unwrap,key
# ExtractNewRecordState configs:
# https://debezium.io/documentation/reference/0.10/configuration/event-flattening.html#configuration_options
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
transforms.unwrap.drop.tombstones=false
transforms.unwrap.delete.handling.mode=rewrite
# transforms.unwrap.add.source.fields=table,lsn
transforms.key.type=org.apache.kafka.connect.transforms.ExtractField$Key
transforms.key.field=uuid

# regex transformer: https://stackoverflow.com/a/50346042/9814131
# transforms.dropSchema.type=org.apache.kafka.connect.transforms.RegexRouter
# # incoming topic name format is like `appl_tracky__postgres.public.api_company`
# # this topic name is determined by debezium postgres source connector
# transforms.dropSchema.regex=appl_tracky([^.]*)[.]([^.]*)[.]([^.]*)
# transforms.dropSchema.replacement=appl_tracky.$3

# Q: but how do we include all tables in database?

# debezium postgres connector topic/table naming convention:
# https://debezium.io/documentation/reference/0.10/connectors/postgresql.html#topic-names
#
# format:
# <serverName == logical name of the connector == database.server.name>.<schema default is `public`>.<table name>

# Solution 1 `RegexRouter`: https://debezium.io/blog/2017/09/25/streaming-to-another-database/#topic_naming
# the post is a bit old but does illustrate the solution using RegexRouter
# another example using RegexRouter, by confluent doc: https://docs.confluent.io/current/connect/transforms/regexrouter.html#regexrouter
# a github issue example using RegexRouter & topic to filter out and do topic/index replacement: https://github.com/confluentinc/kafka-connect-elasticsearch/issues/298#issuecomment-553344534

# Solution 2 `kcql`: https://stackoverflow.com/questions/48942326/kafka-connect-multiple-topics-in-sink-connector-properties
# but we need to figure out how to use regex with kcql

# listing indices: 
# curl http://elasticsearch-master.kube-system.svc.cluster.local:9200/_cat/indices
# https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-indices.html

# update index settings: https://www.elastic.co/guide/en/
# curl -X PUT --header "Content-Type: application/json"  http://elasticsearch-master.kube-system.svc.cluster.local:9200/appl_tracky__postgres.public.api_application/_settings --data '{"index": {"number_of_replicas": 0}}'
# elasticsearch/reference/current/indices-update-settings.html

# how to send json curl: https://stackoverflow.com/questions/7172784/how-do-i-post-json-data-with-curl-from-a-terminal-commandline-to-test-spring-res

# clean up all indeicies
# curl -X DELETE 'http://elasticsearch-master.kube-system.svc.cluster.local:9200/_all'